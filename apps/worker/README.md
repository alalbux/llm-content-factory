# âš™ï¸ apps/worker â€” Content Orchestrator

Este serviÃ§o Ã© o **worker assÃ­ncrono** do projeto **LLM Content Factory**.

Ele consome jobs de uma fila (**BullMQ + Redis**) e executa a **orquestraÃ§Ã£o de conteÃºdo com LLMs**, integrando com o Strapi CMS e serviÃ§os externos (OpenAI).

> Se o `apps/web` Ã© o cÃ©rebro do produto
> o `apps/worker` Ã© o **motor que faz tudo acontecer**.

---

## ðŸŽ¯ Responsabilidades

O worker Ã© responsÃ¡vel por:

* Planejar campanhas de conteÃºdo (LLM Planner)
* Criar tarefas de conteÃºdo por canal
* Gerar drafts automaticamente (LLM Generator)
* Revisar qualidade e risco (LLM Critic)
* Persistir resultados no Strapi
* Controlar status e fluxo assÃ­ncrono
* Garantir retries e isolamento de falhas

Ele **nÃ£o expÃµe API pÃºblica** e **nÃ£o serve UI**.

---

## ðŸ§  Arquitetura (big picture)

```
Next.js (apps/web)
   â”‚
   â”‚ enqueue jobs
   â–¼
BullMQ Queue  â† Redis
   â”‚
   â–¼
apps/worker
   â”œâ”€ Planner (LLM)
   â”œâ”€ Generator (LLM)
   â”œâ”€ Critic (LLM)
   â”‚
   â–¼
Strapi CMS
```

---

## ðŸ§© Principais Jobs

| Job name         | DescriÃ§Ã£o                                       |
| ---------------- | ----------------------------------------------- |
| `plan_campaign`  | Cria tasks de conteÃºdo a partir de uma campanha |
| `generate_task`  | Gera drafts e executa revisÃ£o automÃ¡tica        |
| `review_version` | (futuro) Reavalia conteÃºdo manualmente editado  |

---

## ðŸ“¦ Estrutura do projeto

```
apps/worker/
  src/
    index.ts              # Entry point do worker
    env.ts                # ValidaÃ§Ã£o de variÃ¡veis de ambiente
    queue.ts              # BullMQ + Redis
    strapi.ts             # Client Strapi (REST)
    openai.ts             # Client OpenAI (via fetch)
    orchestrator/
      planner.ts          # LLM Planner
      generator.ts        # LLM Generator
      critic.ts           # LLM Critic
      jobs.ts             # Tipos de jobs
  .env.example
  package.json
  tsconfig.json
```

---

## ðŸ” VariÃ¡veis de ambiente

Crie um `.env` baseado em `.env.example`.

```env
NODE_ENV=development

REDIS_URL=redis://localhost:6379

STRAPI_URL=http://localhost:1337
STRAPI_TOKEN=replace_me

OPENAI_API_KEY=replace_me
OPENAI_MODEL=gpt-4.1-mini

WORKER_CONCURRENCY=5
LOG_LEVEL=info
```

### ObservaÃ§Ãµes

* `REDIS_URL` precisa apontar para um Redis acessÃ­vel
* `STRAPI_TOKEN` deve ter permissÃ£o de **write**
* O worker **nÃ£o funciona sem Redis**

---

## ðŸš€ Como rodar localmente

### 1ï¸âƒ£ Subir o Redis

Via Docker (recomendado):

```bash
docker run -d \
  --name redis-content-factory \
  -p 6379:6379 \
  redis:7-alpine
```

Teste:

```bash
docker exec -it redis-content-factory redis-cli ping
# PONG
```

---

### 2ï¸âƒ£ Preparar o worker

```bash
cd apps/worker
cp .env.example .env
# edite o .env com STRAPI_TOKEN e OPENAI_API_KEY
```

---

### 3ï¸âƒ£ Rodar em modo dev

```bash
npm install
npm run dev
```

VocÃª deve ver algo como:

```
[worker] starting...
```

---

## ðŸ§ª Enfileirando um job (exemplo)

Via cÃ³digo:

```ts
import { queue } from "./src/queue.js";

await queue.add("plan_campaign", { campaignId: 1 });
```

Ou, normalmente, isso Ã© feito automaticamente pelo `apps/web` ao criar uma campanha.

---

## ðŸ”„ Fluxo de execuÃ§Ã£o (simplificado)

1. Recebe job `plan_campaign`
2. Busca campanha no Strapi
3. Executa LLM Planner
4. Cria `ContentTask`s no CMS
5. Enfileira `generate_task` para cada task
6. Gera drafts
7. Executa revisÃ£o automÃ¡tica
8. Salva `ContentVersion` com status:

   * `ready` ou
   * `needs_review`

---

## ðŸ›¡ Guardrails e decisÃµes de design

* LLMs **nÃ£o escrevem direto no CMS final**
* Todo conteÃºdo passa por **critic automÃ¡tico**
* Erros em uma task **nÃ£o derrubam a campanha inteira**
* Jobs sÃ£o idempotentes (planejado)
* Worker Ã© stateless (escala horizontal)

---

## âš ï¸ Erros comuns

### `ECONNREFUSED 127.0.0.1:6379`

âž¡ï¸ Redis nÃ£o estÃ¡ rodando ou nÃ£o acessÃ­vel

### `permission denied /var/run/docker.sock`

âž¡ï¸ UsuÃ¡rio sem permissÃ£o Docker (ver README raiz)

### `OpenAI returned empty content`

âž¡ï¸ Erro de prompt ou limite de API

---

## ðŸ›£ Roadmap do worker

* [ ] RAG com pgvector
* [ ] Retry + backoff configurÃ¡vel
* [ ] IdempotÃªncia por job
* [ ] Observabilidade (logs estruturados)
* [ ] MÃ©tricas de custo por campanha
* [ ] DLQ (dead letter queue)

---

## ðŸ§  Filosofia

> O worker nÃ£o â€œcria conteÃºdoâ€.
> Ele executa **processos editoriais automatizados**.

Se virar sÃ³ um loop de prompt â†’ response, algo deu errado.

---

## ðŸ“Œ Dica final

Se algo falhar:

1. Veja o log do worker
2. Veja o estado no Strapi
3. Veja o job no Redis

**Nunca debuga LLM sem contexto.**


